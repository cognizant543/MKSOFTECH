{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PATHI MAHESH KUMAR\n",
    "## maheshkumarpathi.1999@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are there any duplicated values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yes , but there is no null values in white and red wines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do we need to do feature scaling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yes, We need feature scaling but can't make shur its give perfect value ,\n",
    "but it give estimated value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do we need to generate new features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train and Test dataset. (0.7/0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A machine learning model is a file that has been trained to recognize certain types of patterns. You train a model over a set of data, providing it an algorithm that it can use to reason over and learn from those data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model fitting is a measure of how well a machine learning model generalizes to similar data to that on which it was trained. \n",
    "A model that is well-fitted produces more accurate outcomes. \n",
    "A model that is overfitted matches the data too closely. \n",
    "A model that is underfitted doesn’t match closely enough.\n",
    "\n",
    "Model fitting is the essence of machine learning. If your model doesn’t fit your data correctly, the outcomes it produces will not be accurate enough to be useful for practical decision-making. A properly fitted model has hyperparameters that capture the complex relationships between known variables and the target variable, allowing it to find relevant insights or make accurate predictions.\n",
    "\n",
    "Understanding model fit is important for understanding the root cause for poor model accuracy. \n",
    "This understanding will guide you to take corrective steps. \n",
    "We can determine whether a predictive model is underfitting or overfitting the training data by looking at the prediction error on the training data and the evaluation data.\n",
    "\n",
    "![](https://docs.aws.amazon.com/machine-learning/latest/dg/images/mlconcepts_image5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models for both train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(670, 2) (330, 2) (670,) (330,)\n"
     ]
    }
   ],
   "source": [
    "# split a dataset into train and test sets\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "# create dataset\n",
    "X, y = make_blobs(n_samples=1000)\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.7178792   9.38142849]\n",
      " [-2.68185828  7.99139285]\n",
      " [-2.17975632  7.16695867]\n",
      " [-3.48069054  6.9280198 ]\n",
      " [-3.36230649  8.43486805]]\n",
      "[[-3.7178792   9.38142849]\n",
      " [-2.68185828  7.99139285]\n",
      " [-2.17975632  7.16695867]\n",
      " [-3.48069054  6.9280198 ]\n",
      " [-3.36230649  8.43486805]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrate that the train-test split procedure is repeatable\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "# create dataset\n",
    "X, y = make_blobs(n_samples=100)\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# summarize first 5 rows\n",
    "print(X_train[:5, :])\n",
    "# split again, and we should see the same split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# summarize first 5 rows\n",
    "print(X_train[:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Confusion Matrix and scores of Accuracy, Recall, Precision and F1-Score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.677\n"
     ]
    }
   ],
   "source": [
    "# calculates precision for 1:1:100 dataset with 50tp,20fp, 99tp,51fp\n",
    "from sklearn.metrics import precision_score\n",
    "# define actual\n",
    "act_pos1 = [1 for _ in range(100)]\n",
    "act_pos2 = [2 for _ in range(100)]\n",
    "act_neg = [0 for _ in range(10000)]\n",
    "y_true = act_pos1 + act_pos2 + act_neg\n",
    "# define predictions\n",
    "pred_pos1 = [0 for _ in range(50)] + [1 for _ in range(50)]\n",
    "pred_pos2 = [0 for _ in range(1)] + [2 for _ in range(99)]\n",
    "pred_neg = [1 for _ in range(20)] + [2 for _ in range(51)] + [0 for _ in range(9929)]\n",
    "y_pred = pred_pos1 + pred_pos2 + pred_neg\n",
    "# calculate prediction\n",
    "precision = precision_score(y_true, y_pred, labels=[1,2], average='micro')\n",
    "print('Precision: %.3f' % precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Measure: 0.760\n"
     ]
    }
   ],
   "source": [
    "# calculates f1 for 1:100 dataset with 95tp, 5fn, 55fp\n",
    "from sklearn.metrics import f1_score\n",
    "# define actual\n",
    "act_pos = [1 for _ in range(100)]\n",
    "act_neg = [0 for _ in range(10000)]\n",
    "y_true = act_pos + act_neg\n",
    "# define predictions\n",
    "pred_pos = [0 for _ in range(5)] + [1 for _ in range(95)]\n",
    "pred_neg = [1 for _ in range(55)] + [0 for _ in range(9945)]\n",
    "y_pred = pred_pos + pred_neg\n",
    "# calculate score\n",
    "score = f1_score(y_true, y_pred, average='binary')\n",
    "print('F-Measure: %.3f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse occurrence of overfitting and underfitting. If there is any of them, try to overcome it within a different section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem of Overfitting vs Underfitting finally appears when we talk about the polynomial degree. The degree represents how much flexibility is in the model, with a higher power allowing the model freedom to hit as many data points as possible. An underfit model will be less flexible and cannot account for the data. The best way to understand the issue is to take a look at models demonstrating both situations.\n",
    "\n",
    "First up is an underfit model with a 1 degree polynomial fit. In the image on the left, model function in orange is shown on top of the true function and the training observations. On the right, the model predictions for the testing data are shown compared to the true function and testing data points.\n",
    "\n",
    "![](https://miro.medium.com/max/2880/1*kZfqaD6hl9iYGYXkMwV-JA.png)\n",
    "![](https://miro.medium.com/max/600/1*2RXJ2O-_c2ukaq5p-WQ9tQ.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the best performing model and write your comments about why choose this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Root Mean Squared Error (RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE is the most popular evaluation metric used in regression problems. It follows an assumption that error are unbiased and follow a normal distribution.\n",
    "\n",
    "Here are the key points to consider on RMSE:\n",
    "\n",
    "The power of ‘square root’  empowers this metric to show large number deviations.\n",
    "The ‘squared’ nature of this metric helps to deliver more robust results which prevents cancelling the positive and negative error values. In other words, this metric aptly displays the plausible magnitude of error term.\n",
    "\n",
    "It avoids the use of absolute error values which is highly undesirable in mathematical calculations.\n",
    "\n",
    "When we have more samples, reconstructing the error distribution using RMSE is considered to be more reliable.\n",
    "\n",
    "RMSE is highly affected by outlier values. Hence, make sure you’ve removed outliers from your data set prior to using this metric.\n",
    "\n",
    "As compared to mean absolute error, RMSE gives higher weightage and punishes large errors.\n",
    "\n",
    "RMSE metric is given by:\n",
    "\n",
    "model evaluation, rmse, root mean squared error\n",
    "\n",
    "where, N is Total Number of Observations.\n",
    "\n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2016/02/rmse.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse results and make comment about how you can improve model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes i know mathematics but with the help of mathematics , we are finding many solutions by machine learning.\n",
    "i improved a lot of matter about models not only models also machine learning.\n",
    "\n",
    "\n",
    "Thank you for GLOBALHUB with the hrlp of GlobalHub i get some knowledge on Machine Learning. Thank you so mach .........."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
