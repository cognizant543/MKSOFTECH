{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework1.ipynb\n",
    "PATHI MAHESH KUMAR edited this page yesterday · 1 revision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)How would you define Machine Learning?\n",
    " -Machine learning is an algorithm that allows computers to learn. Machine Learning is a subset of Artificial Intilligence.\n",
    " - It is classified into two types :- \n",
    "                    1) SUPERVISED LEARNING         2)UNSUPERVISED LEARNING\n",
    "![](https://th.bing.com/th/id/OIP.wfb_rGcdVe0-bHKg7EacEQHaEK?w=262&h=180&c=7&o=5&dpr=1.5&pid=1.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) What are the differences between Supervised and Unsupervised            Learning? Specify example 3 algorithms for each of these.\n",
    "SUPERVISED LEARNING\n",
    " - Supervised Learing is a process of learning from the labelled training data by a machine.\n",
    " - Supervised Learning is Classified into 2 types:-\n",
    "\n",
    "       1)Supervised Classification :- \n",
    " \n",
    "\n",
    "\n",
    "       2)Supervised Regression\n",
    "UNSUPERVISED LEARNING\n",
    " - Unsupervised Learning is non labelled and unclarified information in analysis to discover hidden knowledge .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3)What are the test and validation set, and why would you want to use them?\n",
    "\n",
    "-it useful to see exactly how datasets are described by the practitioners and     experts.\n",
    "-Generally, the term “validation set” is used interchangeably with the term “test set” and refers to a sample of the dataset held back from training the model.\n",
    "\n",
    "-The evaluation of a model skill on the training dataset would result in a  biased score. Therefore the model is evaluated on the held-out sample to give an unbiased estimate of model skill. This is typically called a train-test split approach to algorithm evaluation.\n",
    "\n",
    "1)Training Dataset: The sample of data used to fit the model.\n",
    "\n",
    "2)Validation Dataset: The sample of data used to provide an unbiased evaluation of a model fit on the training dataset while tuning model hyperparameters. The evaluation becomes more biased as skill on the validation dataset is incorporated into the model configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) What are the main preprocessing steps? Explain them in detail. Why we need to prepare our data?\n",
    "\n",
    "There are seven significant steps in data preprocessing in Machine Learning:\n",
    "\n",
    "1. Acquire the dataset\n",
    "2. Import all the crucial libraries\n",
    "3. Import the dataset\n",
    "4. Identifying and handling the missing values\n",
    "5. Encoding the categorical data\n",
    "6. Splitting the dataset\n",
    "7. Feature scaling\n",
    "\n",
    "\n",
    "1. Acquire the dataset\n",
    "To build and develop Machine Learning models, you must first acquire the relevant dataset. This dataset will be comprised of data gathered from multiple and disparate sources which are then combined in a proper format to form a dataset. Dataset formats differ according to use cases. For instance, a business dataset will be entirely different from a medical dataset. While a business dataset will contain relevant industry and business data, a medical dataset will include healthcare-related data.\n",
    "\n",
    "There are several online sources from where you can download datasets like https://www.kaggle.com/uciml/datasets and https://archive.ics.uci.edu/ml/index.php. You can also create a dataset by collecting data via different Python APIs. Once the dataset is ready, you must put it in a CSV, or HTML, or XLSX file formats.\n",
    "\n",
    "2. Import all the crucial libraries\n",
    "Since Python is the most extensively used and also the most preferred library by Data Scientists around the world, we’ll show you how to import Python libraries for data preprocessing in Machine Learning. Read more about Python libraries for Data Science here. The predefined Python libraries can perform specific data preprocessing jobs. The three core Python libraries used for this data preprocessing in Machine Learning are:\n",
    "\n",
    "NumPy – NumPy is the fundamental package for scientific calculation in Python. Hence, it is used for inserting any type of mathematical operation in the code. Using NumPy, you can also add large multidimensional arrays and matrices in your code. \n",
    "Pandas – Pandas is an excellent open-source Python library for data manipulation and analysis. It is extensively used for importing and managing the datasets. It packs in high-performance, easy-to-use data structures and data analysis tools for Python.\n",
    "Matplotlib – Matplotlib is a Python 2D plotting library that is used to plot any type of charts in Python. It can deliver publication-quality figures in numerous hard copy formats and interactive environments across platforms (IPython shells, Jupyter notebook, web application servers, etc.). \n",
    "Read: Machine Learning Project Ideas for Beginners\n",
    "\n",
    "3. Import the dataset\n",
    "In this step, you need to import the dataset/s that you have gathered for the ML project at hand. However, before you can import the dataset/s, you must set the current directory as the working directory. You can set the working directory in Spyder IDE in three simple steps:\n",
    "\n",
    "1.Save your Python file in the directory containing the dataset.\n",
    "2.Go to File Explorer option in Spyder IDE and choose the required directory.\n",
    "3.Now, click on the F5 button or Run option to execute the file.\n",
    "data preprocessing in ml\n",
    "\n",
    "Source\n",
    "\n",
    "![](https://www.upgrad.com/blog/wp-content/uploads/2020/01/data-preprocessing-machine-learning-1.png)\n",
    "\n",
    "This is how the working directory should look. \n",
    "\n",
    "Once you’ve set the working directory containing the relevant dataset, you can import the dataset using the “read_csv()” function of the Pandas library. This function can read a CSV file (either locally or through a URL) and also perform various operations on it. The read_csv() is written as:\n",
    "\n",
    "data_set= pd.read_csv(‘Dataset.csv’)\n",
    "\n",
    "In this line of code, “data_set” denotes the name of the variable wherein you stored the dataset. The function contains the name of the dataset as well. Once you execute this code, the dataset will be successfully imported. \n",
    "\n",
    "During the dataset importing process, there’s another essential thing you must do – extracting dependent and independent variables. For every Machine Learning model, it is necessary to separate the independent variables (matrix of features) and dependent variables in a dataset. \n",
    "\n",
    "Consider this dataset:\n",
    "\n",
    "![](https://www.upgrad.com/blog/wp-content/uploads/2020/01/data-preprocessing-machine-learning-2-1.png)\n",
    "\n",
    "Source\n",
    "\n",
    "This dataset contains three independent variables – country, age, and salary, and one dependent variable – purchased. \n",
    "\n",
    "How to extract the independent variables?\n",
    "\n",
    "To extract the independent variables, you can use “iloc[ ]” function of the Pandas library. This function can extract selected rows and columns from the dataset.\n",
    "\n",
    "x= data_set.iloc[:,:-1].values  \n",
    "\n",
    "In the line of code above, the first colon(:) considers all the rows and the second colon(:) considers all the columns. The code contains “:-1” since you have to leave out the last column containing the dependent variable. By executing this code, you will obtain the matrix of features, like this – \n",
    "\n",
    "[[‘India’ 38.0 68000.0]  \n",
    "\n",
    " [‘France’ 43.0 45000.0]  \n",
    "\n",
    " [‘Germany’ 30.0 54000.0]  \n",
    "\n",
    " [‘France’ 48.0 65000.0]  \n",
    "\n",
    " [‘Germany’ 40.0 nan]  \n",
    "\n",
    " [‘India’ 35.0 58000.0]  \n",
    "\n",
    " [‘Germany’ nan 53000.0]  \n",
    "\n",
    " [‘France’ 49.0 79000.0]  \n",
    "\n",
    " [‘India’ 50.0 88000.0]  \n",
    "\n",
    " [‘France’ 37.0 77000.0]] \n",
    "\n",
    "How to extract the dependent variable?\n",
    "\n",
    "You can use the “iloc[ ]” function to extract the dependent variable as well. Here’s how you write it:\n",
    "\n",
    "y= data_set.iloc[:,3].values  \n",
    "\n",
    "This line of code considers all the rows with the last column only. By executing the above code, you will get the array of dependent variables, like so – \n",
    "\n",
    "array([‘No’, ‘Yes’, ‘No’, ‘No’, ‘Yes’, ‘Yes’, ‘No’, ‘Yes’, ‘No’, ‘Yes’],\n",
    "\n",
    "      dtype=object)\n",
    "\n",
    "4. Identifying and handling the missing values\n",
    "In data preprocessing, it is pivotal to identify and correctly handle the missing values, failing to do this, you might draw inaccurate and faulty conclusions and inferences from the data. Needless to say, this will hamper your ML project. \n",
    "\n",
    "Basically, there are two ways to handle missing data:\n",
    "\n",
    "Deleting a particular row – In this method, you remove a specific row that has a null value for a feature or a particular column where more than 75% of the values are missing. However, this method is not 100% efficient, and it is recommended that you use it only when the dataset has adequate samples. You must ensure that after deleting the data, there remains no addition of bias. \n",
    "Calculating the mean – This method is useful for features having numeric data like age, salary, year, etc. Here, you can calculate the mean, median, or mode of a particular feature or column or row that contains a missing value and replace the result for the missing value. This method can add variance to the dataset, and any loss of data can be efficiently negated. Hence, it yields better results compared to the first method (omission of rows/columns). Another way of approximation is through the deviation of neighbouring values. However, this works best for linear data.\n",
    "Read: Applications of Machine Learning Applications Using Cloud\n",
    "\n",
    "5. Encoding the categorical data\n",
    "Categorical data refers to the information that has specific categories within the dataset. In the dataset cited above, there are two categorical variables – country and purchased.\n",
    "\n",
    "Machine Learning models are primarily based on mathematical equations. Thus, you can intuitively understand that keeping the categorical data in the equation will cause certain issues since you would only need numbers in the equations.\n",
    "\n",
    "How to encode the country variable?\n",
    "\n",
    "As seen in our dataset example, the country column will cause problems, so you must convert it into numerical values. To do so, you can use the LabelEncoder() class from the sci-kit learn library. The code will be as follows –\n",
    "\n",
    "#Catgorical data  \n",
    "\n",
    "#for Country Variable  \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "\n",
    "label_encoder_x= LabelEncoder()  \n",
    "\n",
    "x[:, 0]= label_encoder_x.fit_transform(x[:, 0]) \n",
    "\n",
    " And the output will be – \n",
    "\n",
    " Out[15]: \n",
    "\n",
    "  array([[2, 38.0, 68000.0],\n",
    "\n",
    "            [0, 43.0, 45000.0],\n",
    "\n",
    "         [1, 30.0, 54000.0],\n",
    "\n",
    "         [0, 48.0, 65000.0],\n",
    "\n",
    "         [1, 40.0, 65222.22222222222],\n",
    "\n",
    "         [2, 35.0, 58000.0],\n",
    "\n",
    "         [1, 41.111111111111114, 53000.0],\n",
    "\n",
    "         [0, 49.0, 79000.0],\n",
    "\n",
    "         [2, 50.0, 88000.0],\n",
    "\n",
    "        [0, 37.0, 77000.0]], dtype=object)\n",
    "\n",
    " Here we can see that the LabelEncoder class has successfully encoded the variables into digits. However, there are country variables that are encoded as 0, 1, and 2 in the output shown above. So, the ML model may assume that there is come some correlation between the three variables, thereby producing faulty output. To eliminate this issue, we will now use Dummy Encoding.\n",
    "\n",
    "Dummy variables are those that take the values 0 or 1 to indicate the absence or presence of a specific categorical effect that can shift the outcome. In this case, the value 1 indicates the presence of that variable in a particular column while the other variables become of value 0. In dummy encoding, the number of columns equals the number of categories.\n",
    "\n",
    "Since our dataset has three categories, it will produce three columns having the values 0 and 1. For Dummy Encoding, we will use OneHotEncoder class of the scikit-learn library. The input code will be as follows – \n",
    "\n",
    "#for Country Variable  \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder  \n",
    "\n",
    "label_encoder_x= LabelEncoder()  \n",
    "\n",
    "x[:, 0]= label_encoder_x.fit_transform(x[:, 0])  \n",
    "\n",
    "#Encoding for dummy variables  \n",
    "\n",
    "onehot_encoder= OneHotEncoder(categorical_features= [0])    \n",
    "\n",
    "x= onehot_encoder.fit_transform(x).toarray()\n",
    "\n",
    " On execution of this code, you will get the following output –\n",
    "\n",
    " array([[0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 3.80000000e+01,\n",
    "\n",
    "        6.80000000e+04],\n",
    "\n",
    "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.30000000e+01,\n",
    "\n",
    "        4.50000000e+04],\n",
    "\n",
    "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 3.00000000e+01,\n",
    "\n",
    "        5.40000000e+04],\n",
    "\n",
    "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.80000000e+01,\n",
    "\n",
    "        6.50000000e+04],\n",
    "\n",
    "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 4.00000000e+01,\n",
    "\n",
    "        6.52222222e+04],\n",
    "\n",
    "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 3.50000000e+01,\n",
    "\n",
    "        5.80000000e+04],\n",
    "\n",
    "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 4.11111111e+01,\n",
    "\n",
    "        5.30000000e+04],\n",
    "\n",
    "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.90000000e+01,\n",
    "\n",
    "        7.90000000e+04],\n",
    "\n",
    "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 5.00000000e+01,\n",
    "\n",
    "        8.80000000e+04],\n",
    "\n",
    "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.70000000e+01,\n",
    "\n",
    "        7.70000000e+04]])\n",
    "\n",
    " In the output shown above, all the variables are divided into three columns and encoded into the values 0 and 1.\n",
    "\n",
    "How to encode the purchased variable?\n",
    "\n",
    "For the second categorical variable, that is, purchased, you can use the “labelencoder” object of the LableEncoder class. We are not using the OneHotEncoder class since the purchased variable only has two categories yes or no, both of which are encoded into 0 and 1.\n",
    "\n",
    "The input code for this variable will be – \n",
    "\n",
    "labelencoder_y= LabelEncoder()  \n",
    "\n",
    "y= labelencoder_y.fit_transform(y) \n",
    "\n",
    "The output will be – \n",
    "\n",
    "Out[17]: array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1])\n",
    "\n",
    "6. Splitting the dataset\n",
    "Every dataset for Machine Learning model must be split into two separate sets – training set and test set. \n",
    "\n",
    "data preprocessing\n",
    "![](https://www.upgrad.com/blog/wp-content/uploads/2020/01/data-preprocessing-machine-learning-5.png)\n",
    "Source\n",
    "\n",
    "Training set denotes the subset of a dataset that is used for training the machine learning model. Here, you are already aware of the output. A test set, on the other hand, is the subset of the dataset that is used for testing the machine learning model. The ML model uses the test set to predict outcomes. \n",
    "\n",
    "Usually, the dataset is split into 70:30 ratio or 80:20 ratio. This means that you either take 70% or 80% of the data for training the model while leaving out the rest 30% or 20%. The splitting process varies according to the shape and size of the dataset in question. \n",
    "\n",
    " To split the dataset, you have to write the following line of code – \n",
    "\n",
    " from sklearn.model_selection import train_test_split  \n",
    "\n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.2, random_state=0)  \n",
    "\n",
    "Here, the first line splits the arrays of the dataset into random train and test subsets. The second line of code includes four variables:\n",
    "\n",
    "x_train – features for the training data\n",
    "x_test – features for the test data\n",
    "y_train – dependent variables for training data\n",
    "y_test – independent variable for testing data\n",
    "Thus, the train_test_split() function includes four parameters, the first two of which are for arrays of data. The test_size function specifies the size of the test set. The test_size maybe .5, .3, or .2 – this specifies the dividing ratio between the training and test sets. The last parameter, “random_state” sets seed for a random generator so that the output is always the same. \n",
    "\n",
    "7. Feature scaling\n",
    "Feature scaling marks the end of the data preprocessing in Machine Learning. It is a method to standardize the independent variables of a dataset within a specific range. In other words, feature scaling limits the range of variables so that you can compare them on common grounds.\n",
    "\n",
    "Consider this dataset for example – \n",
    "\n",
    "![](https://www.upgrad.com/blog/wp-content/uploads/2020/01/data-preprocessing-machine-learning-7.png)\n",
    "\n",
    "Source\n",
    "\n",
    "In the dataset, you can notice that the age and salary columns do not have the same scale. In such a scenario, if you compute any two values from the age and salary columns, the salary values will dominate the age values and deliver incorrect results. Thus, you must remove this issue by performing feature scaling for Machine Learning.\n",
    "\n",
    "Most ML models are based on Euclidean Distance, which is represented as:\n",
    "\n",
    "![](https://www.upgrad.com/blog/wp-content/uploads/2020/01/1_Ud6qCIDqDEn5k_q3YTaP1g.png)\n",
    "\n",
    "Source\n",
    "\n",
    "You can perform feature scaling in Machine Learning in two ways:\n",
    "\n",
    "Standardization\n",
    "\n",
    "![](https://www.upgrad.com/blog/wp-content/uploads/2020/01/data-preprocessing-machine-learning-9.png)\n",
    "\n",
    "Source \n",
    "\n",
    "Normalization\n",
    "\n",
    "![](https://www.upgrad.com/blog/wp-content/uploads/2020/01/data-preprocessing-machine-learning-10.png)\n",
    "\n",
    "Source \n",
    "\n",
    "For our dataset, we will use the standardization method. To do so, we will import StandardScaler class of the sci-kit-learn library using the following line of code:\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "\n",
    "The next step will be to create the object of StandardScaler class for independent variables. After this, you can fit and transform the training dataset using the following code:\n",
    "\n",
    "st_x= StandardScaler()  \n",
    "\n",
    "x_train= st_x.fit_transform(x_train) \n",
    "\n",
    "For the test dataset, you can directly apply transform() function (you need not use the fit_transform() function because it is already done in training set). The code will be as follows – \n",
    "\n",
    "x_test= st_x.transform(x_test) \n",
    "\n",
    "The output for the test dataset will show the scaled values for x_train and x_test as:\n",
    "\n",
    "![](https://www.upgrad.com/blog/wp-content/uploads/2020/01/data-preprocessing-machine-learning-11.png)\n",
    "\n",
    "Source\n",
    "\n",
    "\n",
    "![](https://www.upgrad.com/blog/wp-content/uploads/2020/01/data-preprocessing-machine-learning-12.png)\n",
    "Source\n",
    "\n",
    "All the variables in the output are scaled between the values -1 and 1.\n",
    "\n",
    "Now, to combine all the steps we’ve performed so far, you get: \n",
    "\n",
    " \n",
    "\n",
    "### importing libraries  \n",
    "\n",
    "import numpy as nm  \n",
    "\n",
    "import matplotlib.pyplot as mtp  \n",
    "\n",
    "import pandas as pd  \n",
    "\n",
    "  \n",
    "\n",
    "#importing datasets  \n",
    "\n",
    "data_set= pd.read_csv(‘Dataset.csv’)  \n",
    "\n",
    "  \n",
    "\n",
    "#Extracting Independent Variable  \n",
    "\n",
    "x= data_set.iloc[:, :-1].values  \n",
    "\n",
    "  \n",
    "\n",
    "#Extracting Dependent variable  \n",
    "\n",
    "y= data_set.iloc[:, 3].values  \n",
    "\n",
    "  \n",
    "\n",
    "#handling missing data(Replacing missing data with the mean value)  \n",
    "\n",
    "from sklearn.preprocessing import Imputer  \n",
    "\n",
    "imputer= Imputer(missing_values =’NaN’, strategy=’mean’, axis = 0)  \n",
    "\n",
    "  \n",
    "\n",
    "#Fitting imputer object to the independent varibles x.   \n",
    "\n",
    "imputerimputer= imputer.fit(x[:, 1:3])  \n",
    "\n",
    "  \n",
    "\n",
    "#Replacing missing data with the calculated mean value  \n",
    "\n",
    "x[:, 1:3]= imputer.transform(x[:, 1:3])  \n",
    "\n",
    "  \n",
    "\n",
    "#for Country Variable  \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder  \n",
    "\n",
    "label_encoder_x= LabelEncoder()  \n",
    "\n",
    "x[:, 0]= label_encoder_x.fit_transform(x[:, 0])  \n",
    "\n",
    "  \n",
    "\n",
    "#Encoding for dummy variables  \n",
    "\n",
    "onehot_encoder= OneHotEncoder(categorical_features= [0])    \n",
    "\n",
    "x= onehot_encoder.fit_transform(x).toarray()  \n",
    "\n",
    "  \n",
    "\n",
    "#encoding for purchased variable  \n",
    "\n",
    "labelencoder_y= LabelEncoder()  \n",
    "\n",
    "y= labelencoder_y.fit_transform(y)  \n",
    "\n",
    "  \n",
    "\n",
    "### Splitting the dataset into training and test set.  \n",
    "\n",
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.2, random_state=0)  \n",
    "\n",
    "  \n",
    "\n",
    "#Feature Scaling of datasets  \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "\n",
    "st_x= StandardScaler()  \n",
    "\n",
    "x_train= st_x.fit_transform(x_train)  \n",
    "\n",
    "x_test= st_x.transform(x_test)  \n",
    "\n",
    " \n",
    "\n",
    "So, that’s data processing in Machine Learning in a nutshell!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5)How you can explore countionus and discrete variables?\n",
    "\n",
    "Discrete variables are countable in a finite amount of time. For example, you can count the change in your pocket. You can count the money in your bank account. You could also count the amount of money in everyone’s bank accounts. It might take you a long time to count that last item, but the point is—it’s still countable.\n",
    "\n",
    "Discrete variables on a scatter plot.\n",
    "\n",
    "![](https://www.statisticshowto.com/wp-content/uploads/2013/09/scatter-plot-2.jpg)\n",
    "\n",
    "What is a Continuous Variable?\n",
    "\n",
    "Continuous Variables would (literally) take forever to count. In fact, you would get to “forever” and never finish counting them. For example, take age. You can’t count “age”. Why not? Because it would literally take forever. For example, you could be:\n",
    "25 years, 10 months, 2 days, 5 hours, 4 seconds, 4 milliseconds, 8 nanoseconds, 99 picosends…and so on.\n",
    "discrete vs continuous variables\n",
    "Time is a continuous variable.\n",
    "\n",
    "![](https://www.statisticshowto.com/wp-content/uploads/2009/08/clock-230x230.jpg)\n",
    "\n",
    "You could turn age into a discrete variable and then you could count it. For example:\n",
    "A person’s age in years.\n",
    "A baby’s age in months.\n",
    "Take a look at this article on orders of magnitude of time and you’ll see why time or age just isn’t countable. Try counting your age in Planctoseconds (good luck…see you at the end of time!).\n",
    "\n",
    "Discrete vs Continuous variables: Steps\n",
    "Step 1: Figure out how long it would take you to sit down and count out the possible values of your variable. For example, if your variable is “Temperature in Arizona,” how long would it take you to write every possible temperature? It would take you literally forever:\n",
    "\n",
    "50°, 50.1°, 50.11°, 50.111°, 50.1111°, …\n",
    "\n",
    "If you start counting now and never, ever, ever finish (i.e. the numbers go on and on until infinity), you have what’s called a continuous variable.\n",
    "\n",
    "If your variable is “Number of Planets around a star,” then you can count all of the numbers out (there can’t be an infinite number of planets). That is a discrete variable.\n",
    "\n",
    "Step 2: Think about “hidden” numbers that you haven’t considered. For example: is time a discrete or continuous variable? You might think it’s continuous (after all, time goes on forever, right?) but if we’re thinking about numbers on a wristwatch (or a stop watch), those numbers are limited by the numbers or number of decimal places that a manufacturer has decided to put into the watch. It’s unlikely that you’ll be given an ambiguous question like this in your elementary stats class but it’s worth thinking about!\n",
    "\n",
    "![](https://www.statisticshowto.com/wp-content/uploads/2014/01/graph-of-4-5x+3-295x300.png)\n",
    "\n",
    "graph\n",
    "This graph of -4/5x+3 has continuous variables — it could go on forever…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5)Analyse the plot given below. (What is the plot and variable type, check the distribution and make comment about how you can preproccess it.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAXoAAAEGCAYAAABrQF4qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXhV5bn38e+dkBACCSEkgTCGUSYZJIKICjgVrVOrR0Gtc/GoaNvzdvKcvtpj386n9VirtVRxrKh1aFGxDlURUYagzIhAmEIYAmGeEsL9/pFFu40J2ZAddrLy+1zXvrL3mvadTfjlybOe9Sxzd0REJLwS4l2AiIjULwW9iEjIKehFREJOQS8iEnIKehGRkGsW7wKqk5WV5Xl5efEuQ0Sk0Zg3b95Wd8+ubl2DDPq8vDwKCgriXYaISKNhZmtrWqeuGxGRkFPQi4iEnIJeRCTkFPQiIiGnoBcRCTkFvYhIyCnoRURCTkEvIhJyCnoRkZBrkFfGSt08O3vdUddfPbzLCapERBoCtehFREJOQS8iEnIKehGRkFPQi4iEnIJeRCTkFPQiIiGnoBcRCTkFvYhIyCnoRURCTkEvIhJyCnoRkZCrda4bM5sMXARscfcB1az/HnBNxPH6AtnuXmpma4DdQAVwyN3zY1W4iIhEJ5oW/RPA2JpWuvuv3X2wuw8G7gamu3tpxCZjgvUKeRGROKg16N39A6C0tu0C44EpdapIRERiKmZ99GaWSmXL/6WIxQ68ZWbzzGxCLftPMLMCMysoKSmJVVkiIk1eLE/GXgzMrNJtM9LdTwEuAO4ws7Nq2tndJ7l7vrvnZ2dnx7AsEZGmLZZBP44q3TbuXhx83QK8AgyL4fuJiEgUYhL0ZtYaGAX8LWJZSzNLO/IcOB9YHIv3ExGR6EUzvHIKMBrIMrMi4F4gCcDdHwk2+xrwlrvvjdi1HfCKmR15n2fd/e+xK11ERKJRa9C7+/gotnmCymGYkcsKgUHHW5iIiMSGrowVEQk5Bb2ISMgp6EVEQk5BLyIScgp6EZGQU9CLiIScgl5EJOQU9CIiIaegFxEJOQW9iEjIKehFREJOQS8iEnIKehGRkFPQi4iEnIJeRCTkFPQiIiGnoBcRCTkFvYhIyNUa9GY22cy2mFm1N/Y2s9FmttPM5gePeyLWjTWz5Wa20sx+GMvCRUQkOtG06J8AxtayzQx3Hxw87gMws0TgIeACoB8w3sz61aVYERE5drUGvbt/AJQex7GHASvdvdDdy4DngEuP4zgiIlIHseqjH2FmC8zsDTPrHyzrCKyP2KYoWFYtM5tgZgVmVlBSUhKjskREJBZB/wnQ1d0HAQ8Cfw2WWzXbek0HcfdJ7p7v7vnZ2dkxKEtERCAGQe/uu9x9T/B8GpBkZllUtuA7R2zaCSiu6/uJiMixqXPQm1l7M7Pg+bDgmNuAuUAvM+tmZsnAOGBqXd9PRESOTbPaNjCzKcBoIMvMioB7gSQAd38EuAK4zcwOAfuBce7uwCEzmwi8CSQCk919Sb18FyIiUqNag97dx9ey/vfA72tYNw2YdnyliYhILOjKWBGRkFPQi4iEnIJeRCTkFPQiIiGnoBcRCTkFvYhIyCnoRURCTkEvIhJyCnoRkZBT0IuIhJyCXkQk5BT0IiIhp6AXEQk5Bb2ISMgp6EVEQk5BLyIScgp6EZGQU9CLiIScgl5EJORqDXozm2xmW8xscQ3rrzGzhcHjIzMbFLFujZktMrP5ZlYQy8JFRCQ60bTonwDGHmX9amCUuw8EfgJMqrJ+jLsPdvf84ytRRETqolltG7j7B2aWd5T1H0W8nAV0qntZIiISK7Huo78ZeCPitQNvmdk8M5twtB3NbIKZFZhZQUlJSYzLEhFpumpt0UfLzMZQGfRnRCwe6e7FZpYDvG1mn7n7B9Xt7+6TCLp98vPzPVZ1iYg0dTFp0ZvZQOBR4FJ333ZkubsXB1+3AK8Aw2LxfiIiEr06B72ZdQFeBr7h7p9HLG9pZmlHngPnA9WO3BERkfpTa9eNmU0BRgNZZlYE3AskAbj7I8A9QFvgYTMDOBSMsGkHvBIsawY86+5/r4fvQUREjiKaUTfja1l/C3BLNcsLgUFf3kNERE4kXRkrIhJyCnoRkZBT0IuIhFzMxtGLNAXPzl5X6zZXD+9yAioRiZ5a9CIiIaegFxEJOQW9iEjIKehFREJOQS8iEnIKehGRkFPQi4iEnIJeRCTkFPQiIiGnoBcRCTkFvYhIyCnoRURCTkEvIhJyCnoRkZCLKujNbLKZbTGzam/ubZV+Z2YrzWyhmZ0Sse56M1sRPK6PVeEiIhKdaFv0TwBjj7L+AqBX8JgA/AHAzDKpvJn4cGAYcK+ZtTneYkVE5NhFFfTu/gFQepRNLgWe8kqzgAwzywW+Arzt7qXuvh14m6P/whARkRiLVR99R2B9xOuiYFlNy7/EzCaYWYGZFZSUlMSoLBERiVXQWzXL/CjLv7zQfZK757t7fnZ2dozKEhGRWAV9EdA54nUnoPgoy0VE5ASJVdBPBa4LRt+cBux0943Am8D5ZtYmOAl7frBMREROkGbRbGRmU4DRQJaZFVE5kiYJwN0fAaYBFwIrgX3AjcG6UjP7CTA3ONR97n60k7oiIhJjUQW9u4+vZb0Dd9SwbjIw+dhLExGRWNCVsSIiIaegFxEJOQW9iEjIKehFREJOQS8iEnIKehGRkFPQi4iEnIJeRCTkFPQiIiGnoBcRCTkFvYhIyCnoRURCTkEvIhJyCnoRkZBT0IuIhJyCXkQk5BT0IiIhp6AXEQm5qILezMaa2XIzW2lmP6xm/f1mNj94fG5mOyLWVUSsmxrL4kVEpHa13jPWzBKBh4DzgCJgrplNdfelR7Zx9+9EbH8nMCTiEPvdfXDsShYRkWMRTYt+GLDS3QvdvQx4Drj0KNuPB6bEojgREam7aIK+I7A+4nVRsOxLzKwr0A14N2JxipkVmNksM7vsuCsVEZHjUmvXDWDVLPMath0HvOjuFRHLurh7sZl1B941s0XuvupLb2I2AZgA0KVLlyjKEhGRaETToi8COke87gQU17DtOKp027h7cfC1EHifL/bfR243yd3z3T0/Ozs7irJERCQa0QT9XKCXmXUzs2Qqw/xLo2fM7CSgDfBxxLI2ZtY8eJ4FjASWVt1XRETqT61dN+5+yMwmAm8CicBkd19iZvcBBe5+JPTHA8+5e2S3Tl/gj2Z2mMpfKr+IHK0jIiL1L5o+etx9GjCtyrJ7qrz+cTX7fQScXIf6RESkjnRlrIhIyCnoRURCTkEvIhJyCnoRkZCL6mSsiETv2dnrjrr+6uGxuSCwtveJ5XtJ46YWvYhIyCnoRURCTkEvIhJyCnoRkZBT0IuIhJxG3YiE2IkaASQNm1r0IiIhp6AXEQk5Bb2ISMgp6EVEQk5BLyIScgp6EZGQU9CLiIScgl5EJOSiCnozG2tmy81spZn9sJr1N5hZiZnNDx63RKy73sxWBI/rY1m8iIjUrtYrY80sEXgIOA8oAuaa2VR3X1pl0+fdfWKVfTOBe4F8wIF5wb7bY1K9iIjUKpoW/TBgpbsXunsZ8BxwaZTH/wrwtruXBuH+NjD2+EoVEZHjEU3QdwTWR7wuCpZVdbmZLTSzF82s8zHui5lNMLMCMysoKSmJoiwREYlGNEFv1SzzKq9fBfLcfSDwDvDkMexbudB9krvnu3t+dnZ2FGWJNB7uTsVhx73aH3+RehXN7JVFQOeI152A4sgN3H1bxMs/Ab+M2Hd0lX3fP9YiRRqD/WUVrC3dS/GOA2zauZ/t+8rZdaCcfWUVVByuDPgEg5+/8RkZqUm0T0+hQ0YLTmqfRt/cNPq0Tye3dQpm1bWPRI5fNEE/F+hlZt2ADcA44OrIDcws1903Bi8vAZYFz98EfmZmbYLX5wN317lqkQZi5/5y5q/fwWcbd7F++z6CPCezZTJtWybTPj2F1OaJNEtIIDEBDlU43bJbsn1vGZt2HWDe2u1MXfCvdlPrFkkM6JjOiO5tGdGjLQM7ZZCUqFHQUje1Br27HzKziVSGdiIw2d2XmNl9QIG7TwXuMrNLgENAKXBDsG+pmf2Eyl8WAPe5e2k9fB8iJ4y78/nm3cxctY1VW/bgQMeMFpzVO5ue2a3okNGClKTEGvevOgf8rgPlfL5pN8s27WbZxl18um4H//PW5wCkJidyal4mZ/bK4rx+7ejatmV9fmsSUtYQ+wzz8/O9oKAg3mU0WrrZRP1wd+5+eRHvLd/C5l0Had0iiaFd2zCkcwZtWzWP+jjRfP7b95Yxe/U2PlpV+Vi5ZQ8APXNacW7fdpzXL4dlG3eTUMduHv0shIeZzXP3/OrW6Q5TIlGYXbiNn01bxoKineSkNeffhnZiYKcMEhPqpz+9Tctkxg7IZeyAXADWl+7jnWWbeWfZZh6dUcgj01eRntKMkzu2ZlDnDDpmtIhr335tjQvQL5V4UtA3IeUVh9m86wDPzl7Hlt0HAEhKTKB3uzRO7tiadunNdSKwitK9Zfz09WW89EkRua1TuOKUTgzuklHnlvSx6pyZyo0ju3HjyG7s3F/O+8u38Mj7q5hVWMrMVdvIbJnMwE6tGdQpg3bpKSe0Nmn4FPQh5+6sK93H3DXbWbRhB+UVNXfV9cppxRVDO/G1IR3JUVgwbdFGfvTXxezaX87to3tw59m9eOXTDfEui9Ytkrh0cEf2Hqxgf1kFS4p3srBoJ9OXl/D+8hLap6cwuHMGQ7pkkJaSFO9ypQFQ0IfYxp37eW3hRlZv3UtyswQGd86gV04at43uQceMFgDsL6/gs027mL9+J68vLObnb3zGb976nG+M6MrEMT1p0zI5zt/Fibf7QDn3Tl3Cy59sYGCn1vzqm8Pp0z493mVVq0VyIvl5meTnZbL7QDmLN+xkQdFO/r5kE28t3cRJ7dLIz8ukd7u0eutmkoZPQR9C5RWHeWPxJmYXbqNFciIXD8zllK5taN6sciRI58zUf27bsnkzhnbNZGjXTG4+oxurSvYwaXohj89czQtz1/O9sSdx7fCuJDSRkFi8YSe3//kTirbv465zenHn2T0bzfDGtJQkRvTIYkSPLEp2H2Te2lI+WbeDZZvWkta8GUPz2jAsL5OM1Kb3y7upU9CHzOqte3lk+io27jzAad3bcl7fdrRIrnmoX1U9slvxyysGcsuZ3bjvtaXc87cl/H3xJn55+cAv/IIIo+fmrOOeqUvITE3mhVtHkJ+XGe+Sjlt2WnPGDsjlvH7t+XzzbuauKWX68hI++LyEvrnpnNa9Ld2zNFSzqVDQh8j7y7cw8dlPqTjsXD+iKyfV0N0QzQgJgLH925PVsjmvL97IefdP58r8zl/owmhIoyjqMqT0UMVh/vvVpTw9ay1n9srif68afEzDJRuyxASjb246fXPTgyGbpcxdU8qS4l3kpDUnqVkClw3uSHKzxvFXixwfBX1IvDSviB+8tJDe7dK4aGBuTP48NzNO7ZZJj5xWPDt7LU99vJaz++Rwdp+cEz7qpL7s3F/OxGc/YcaKrdx6Vne+P7ZPaPuyK4dstuecvjksLNrJR6u28v0XF/Lbtz7n5jO6MX54F1o1VySEkX6Nh8DkD1fzf/6ygGHdMnn+1tNi3geb2TKZW0f14JQubXj3sy08P3c95RWHY/oe8bB2216+/vBMPl61jV9dPpC7L+wb2pCPlJSYwNCubZg4pidP3jSMvKxUfjptGaf//B/85q3l7NxXHu8SJcb067uRe/KjNdz32lLG9m/PA+MH//OEa6wlJSZw+SkdaZfenDcWb2LXgXIuGdSh0Y7KmV24jX9/Zh4OPHPLcE7r3jbeJZ1wZsao3tmM6p3Np+u288j0VTz47kqe/GgNt47qwQ2n59FSLfxQUIu+EZsyZx33Tl3CuX3b8eDVQ+ot5I8wM87slc34YV3YsH0/lz/yEeu27avX96wPfylYz7WPzaZNy2T+evvIJhnyVQ3p0oY/fiOfaXedybBumfz6zeWM+vV7TP5wNQfKK+JdntSRgr6RemPRRv7zlUWM6p3NQ9cMOaFDAE/u2JqbRnajdG8ZX//DTBas33HC3rsuDh92fv7GMr734kKGd2vLK7eNJE8jT76gX4d0Hr3+VF6+/XR6t0vjvteWcs5vpvP6wo2aS78R099ljdCc1aV86/n5DOmcwSPXDq33lnx18rJa8tJtp3PD43MYN2kWv796COf0bXfC64jW3oOH+Pbz83l76WauPa0L917cv9GMj69PRxutdNHADvRpn87Hhdu449lPOK17Jvde3J++ucd38Zgm24sf/aQ3Miu37OGbTxXQKaMFj11/6jGNkY+1HtmtePm2kfTMacU3nypgypzohm2eaDv2lfFvj3zMP5Zt5scX9+Mnlw5QyEepZ04rXrvzDP7fZQNYvmk3X/3dDH7010Vs31sW79LkGOinvRHZua+cW56cS1Ki8eRNwxrEidDstOY8N+E0zuqdzd0vL+K3by1vUH/ir9m6l4ffX8W60n08dsOp3DCymyZuO0aJCca1p3Xlve+O5roReUyZs55zfjudv83f0KD+raVmCvpG4lDFYSZO+YQNO/bzyLVDG9RVqi2bN+NP1+VzZX4nfvfuSr7/4sK4D790d2YVbuPRDwtp3iyBV24/nTEn5cS1psYuIzWZH1/Sn9fvOoMumal867n53PjEXIq2N74T8k2Ngr6R+Nm0z5ixYis/vezkBnlpflJiAr+8fCDfOqcXf5lXxE1PzI3beOxDFYd55dMNTF1QTK+cNG4f3ZNe7dLiUksY9Wmfzku3nc69F/djzupSzr//A2au3Mphte4bLAV9I/BCwXomz1zNjSPzuPLUzrXvECdmxnfO682vLh/IrMJtXPbwTFZu2X1Ca9i5v5w/zSikYO12xpyUzTdGdI3reYywSkwwbhzZjbe+cxbDumXy+qKN/GlGIaXqu2+Qohp1Y2ZjgQeovGfso+7+iyrr/wO4hcp7xpYAN7n72mBdBbAo2HSdu18So9qbhHlrS/nRK4s5o2cW/3Vh33iXE5UrT+1Mt+yW3PbMPC576CN+/vWTuXhQh3p/30UbdvLXTzdQ4c7Vw7owoGPrY9o/2jmA5F86tUnl8RtO5XsvLuTVBcX87t0VXHRyLkO7ttG5kAak1ha9mSUCDwEXAP2A8WbWr8pmnwL57j4QeBH4VcS6/e4+OHgo5I9B8Y793Pr0J+RmpPD7q4fQrBGNFDk1L5OpE8+gV7tW3DnlU37w4kL2lR2ql/favreMvxSsZ8qcdbRtlczEMT2POeTl+JkZp3Rpw7fO6UWnjBa8/OkGnpm1lj0H6+ffW45dNMkxDFjp7oXuXgY8B1wauYG7v+fuR87IzAI6xbbMpmd/WQUTni7gQHkFj16X3yjnEO+Q0YIXbh3BHWN68MK89Zx//we8+9nmmB3f3XlxXhHn/HY6C4p2MOakbG49qwdZIZl5srHJSE3mpjO6ceHJuazYsocH3vmc5ZtObNedVC+aoO8IrI94XRQsq8nNwBsRr1PMrMDMZpnZZTXtZGYTgu0KSkpKoigrvNyd77+0kCXFu3hg3OBGfSIxKTGB732lD89PGEFKUiI3PVHAN58qYNnGXcd9THfnH8s2c9GDH/Ldvywgr20qE8f04rx+7ZvEpGQNWYIZZ/TM4o4xPUlLSeLJj9cwbdFGDh1u/JPgNWbR9NFX9z+n2tPrZnYtkA+Miljcxd2Lzaw78K6ZLXL3VV86oPskYBJAfn5+kz59//D7q3h1QTHfH3tSg77a9FgM65bJtLvO5NEPC3n4vVVcsHQG5/VrxzXDuzCyZ1ZUFzDt3F/O1PkbmDJnPUs37qJLZiq/+bdBfG1IR56bu77W/eXEaZeewm2je/DG4o18uHIra7btZdypXchsANd+NEXRBH0REDnUoxNQXHUjMzsX+C9glLsfPLLc3YuDr4Vm9j4wBPhS0Euld5Zu5n/eWs4lgzpw26ge8S4nppKbJXD76J5cM6wrj3+0msdnruHtpZvJbJnM6N7ZDOjYmj7t00hvkURKUiK7D5SzcecBlm/azceF25i/bgdlFYfpm5vOL75+MpcP7aQrXBuwpMQELhnUke5ZrXj50yIefHcFXxvSkYGdMuJdWpMTTdDPBXqZWTdgAzAOuDpyAzMbAvwRGOvuWyKWtwH2uftBM8sCRvLFE7US4fPNu/nWc58yoENrfnXFwNCOWmidmsS3z+3NbaN7MH15Ca8urGz1vfzphmq3N4MBHVpzw8g8Lh7YgQEd0xv1ZxPN6J4wzfsyoGNrOrZpwfNz1/Pc3PWs3LKHiwZ20F2tTqBag97dD5nZROBNKodXTnb3JWZ2H1Dg7lOBXwOtgL8E/wGPDKPsC/zRzA5TeT7gF+6+tJ6+l0Zt256D3PJkAanNmzHpuqGkJIV/7HfzZomc37895/dvD8CWXQdYuWUPew4eYn95BWkpzWif3oJOmS1IT0mKc7VSF21Sk/nmmd35x7LNTP+8hLWl+xh/ahfat06Jd2lNQlTj6N19GjCtyrJ7Ip6fW8N+HwEn16XApuBAeQW3PFXA5l0HmDLhNHJbt4h3SXGRk55CTrr+44dVYoJxfv/2dM9uxQsF63n4/ZV8dWAuw/IyG/VfaI2B/naKs4rDzrefm8/89Tt4YNxgTunSJt4lidSrnjmtuPPsnnTLasnf5hfz7Jx17C/TzU3qk4I+zn42bRl/X7KJH321H2MH5Ma7HJETIi0lietPz+OCAe1ZtnEXD767goI1pfEuK7QU9HH0xMzVPPbham44PY+bz+gW73JETqiE4NaUt57Vg4QE46pJs3jovZVUHG7So6vrhYI+Tt5ason/fm0p5/drx/+9qOqMEiJNR+fMVCaO6cmFJ+fy6zeX843HZrN514F4lxUqupVgHMxcuZWJUz5lYKcMHhg3RFdzngCasOz4nYjPLiUpkd+NG8yZPbO4Z+piLnhgBr+5cpDuIRAjatGfYHPXlHLLkwV0z2rJEzfE91aAIg2JmXHlqZ157c4zyElrzo2Pz+Unry3lQLlO1NaVgv4Emre2lBsfn0tuRgpP3zy8QdwKUKSh6ZmTxl/vGMl1I7ry2Ier+ervZjB//Y54l9WoKehPkA9XbOXaR+eQk9acZ285jew0zbAoUpOUpETuu3QAT900jH1lFXz94Zn88u+fcfCQWvfHQ0F/Ary1ZBM3PTmXrm1Tef7WEboaUCRKZ/XO5s3vnMUVQzvxh/dXcfGDH7JArftjpqCvR+7OozMKufWZefTNTee5CWrJixyr9JQkfnXFIB6/8VR27i/nsodn8p+vLGK7blsYNY26qSdlhw5z32tLeGbWOsb2b8/9Vw3WiVeJmkYJfdmYk3J4+z9Gcf/bn/PUx2t5Y9FGvj+2D1fldyZBI9eOSi36erBhx36u/OPHPDNrHbee1Z2HrzlFIS8SA+kpSdx7cX9eu/MMeuWkcffLi/jawzOZt1ZX1R6Ngj7G/r54I1/93QxWbtnDw9ecwt0X9lVrQyTG+uam8/ytp/G/Vw2meOcBLv/Dx9zw+BwWFqn/vjrquomR0r1l3PO3xby2cCMDOqbz4PhT6JbVMt5liYSWmXHZkI6c378dT360lj9+sIpLfj+T8/q14z/O603f3PR4l9hgKOjrqLziMH+etZb731nBvrJDfPf83tw6qofufCRygqQmN+O20T249rQuPD5zDX+aUcgFD8xgVO9srhvRldEn5TT5q88V9Mep4rAzbdFGHvjHClZu2cPInm2556L+nNS+8d7IW6QxS0tJ4q5zenH9iDye+GgNf569lpufLKBzZguuHd6VK/M7N9mLFM294c0Ul5+f7wUFBfEuo1p7Dx7ib/OLeXRGIYVb99IzpxU/GNuHc/vmNJibJzSmERuxumVeY/qepXqxvn1iecVh3lyyiac+Xsuc1aUkN0vgrF7ZXDCgPef2a0frFuG6a5mZzXP3/OrWqUUfhYrDzpzVpby6sJip84vZc/AQ/Tuk8/A1pzC2f3udbBVpgJISE7hoYAcuGtiBzzbt4oW5RbyxeCPvLNtMUqIxsmcW5/drz2ndM+mW1bLBNNTqg4K+Blt2H+DjVduYsWIr7y8vYeueg7RISuSCk9tz7WldGdI5I9Q/GCJh0qd9Ovdc3I8ffbUvC4p28MbiTUxbtJH3ly8CICetOcO6ZTK8e1uGdM6gZ06rUN23OaqgN7OxwANU3hz8UXf/RZX1zYGngKHANuAqd18TrLsbuBmoAO5y9zdjVn0M7C+roHDrHlaV7KWwZA8rtuxhwfodFG3fD0BGahIje2Zx4YBcxvTJJjVZvxtFGquEBGNIlzYM6dKGuy/ow6qSvcxevY3ZhaXMXr2N1xZuBCrvb5vXNpU+7dPp3S6NvKxUOma0oENGC9qlpzS6k7u1ppaZJQIPAecBRcBcM5vq7ksjNrsZ2O7uPc1sHPBL4Coz6weMA/oDHYB3zKy3u9fLzEQrNu9mb1kF+8oOcaC8gn1llY8jz3fsK2frnoNs3XOQkt2VXzfvOhjxvUKnNi0Y1DmDG07P49S8TAZ0bN3o/lFFpHZmRs+cVvTMacU1w7vi7qwr3ceiDTtZvmk3yzftZnHxTqYt3kjkqcxmCUa79BSyWiXTpmUybVIrHxmpSaQmJ9IiOZEWScEj+V9fExOMBLN/fk0w/vkc4LA7CWZ0zkyN+fcaTfN0GLDS3QuDD+c54FIgMugvBX4cPH8R+L1V9mtcCjzn7geB1Wa2Mjjex7Ep/4suevBDDh46XOP6pEQjq1Vzslo1JyetOf1y0+mSmUqPnFZ0z25JXtuWofpzTUSiZ2Z0bduSrm1bctHAfy3fX1bBhh37KNq+n+IdB9iwYx/FOw5QureM0r1lrNyyhx37ytlz8FCda8hq1ZyCH51b5+NUFU3QdwTWR7wuAobXtI27HzKznUDbYPmsKvt2rO5NzGwCMCF4ucfMlkdR2zFbWR8HPfGygK3xLiIWrqm/Q4fmM6pHDeozqsefhbo4oZ/RWsD+73Hv3rWmFdEEfXX9FlXHZNa0TTT7Vi50nwRMiqKeJs/MCmoaRiWV9BnVTp9R7cLyGUVz+WYR0DnidSeguKZtzKwZ0BoojeIsP+MAAAXNSURBVHJfERGpR9EE/Vygl5l1M7NkKk+uTq2yzVTg+uD5FcC7Xnkl1lRgnJk1N7NuQC9gTmxKFxGRaNTadRP0uU8E3qRyeOVkd19iZvcBBe4+FXgMeDo42VpK5S8Dgu1eoPLE7SHgjvoacdPEqIurdvqMaqfPqHah+Iwa5BQIIiISO5piUUQk5BT0IiIhp6BvZMxsrJktN7OVZvbDeNfT0JjZZDPbYmaL411LQ2Vmnc3sPTNbZmZLzOxb8a6pITGzFDObY2YLgs/nv+NdU12pj74RCaaj+JyI6SiA8VWmo2jSzOwsYA/wlLsPiHc9DZGZ5QK57v6JmaUB84DL9HNUKbiqv6W77zGzJOBD4FvuPquWXRsstegbl39OR+HuZcCR6Sgk4O4fUDnyS2rg7hvd/ZPg+W5gGTVcsd4UeaU9wcuk4NGoW8QK+saluuko9B9UjpuZ5QFDgNnxraRhMbNEM5sPbAHedvdG/fko6BuXqKeUEKmNmbUCXgK+7e674l1PQ+LuFe4+mMqr+YeZWaPuBlTQNy6aUkJiIuh7fgn4s7u/HO96Gip33wG8D4yNcyl1oqBvXKKZjkLkqIKTjY8By9z9t/Gup6Exs2wzywietwDOBT6Lb1V1o6BvRNz9EHBkOoplwAvuviS+VTUsZjaFyvsdnGRmRWZ2c7xraoBGAt8Azjaz+cHjwngX1YDkAu+Z2UIqG1dvu/trca6pTjS8UkQk5NSiFxEJOQW9iEjIKehFREJOQS8iEnIKehGRkFPQS6NmZjeYWYcotnvCzK44juP/u5ldV83yvCMzZJrZ4MjhiWb2YzP7bhTHNjN718zSj7Wuao71jpm1qetxJJwU9NLY3QDUGvTHy90fcfenatlsMHA849AvBBbEaPqBp4HbY3AcCSEFvTQYQSv5MzN70swWmtmLZpYarBtqZtPNbJ6ZvWlmuUELPR/4c3DRTwszu8fM5prZYjObFFwFWtP75ZjZvOD5IDNzM+sSvF5lZqmRrfOghgVm9jFwR7AsGbgPuCqo4arg8P3M7H0zKzSzu2oo4RrgbxH1XBd83wvM7Olg2RNm9odg/vhCMxsVzLm/zMyeiDjWVGD8MX7k0kQo6KWhOQmY5O4DgV3A7cG8LA8CV7j7UGAy8FN3fxEoAK5x98Huvh/4vbufGsxF3wK4qKY3cvctQErQdXJmcKwzzawrsMXd91XZ5XHgLncfEXGMMuAe4PmghueDVX2Ar1A5tfS9wfdQ1Ugq54LHzPoD/wWc7e6DgMibgbQBzga+A7wK3A/0B042s8FBHduB5mbWtqbvV5ouBb00NOvdfWbw/BngDCrDfwDwdjB17I+onNCtOmPMbLaZLaIyHPvX8n4fURm4ZwE/C76eCcyI3MjMWgMZ7j49WPR0Lcd93d0PuvtWKqe6bVfNNpnBfPAEtb4YbI+7R86p/6pXXsK+CNjs7ovc/TCwBMiL2G4L9diNJY1Xs3gXIFJF1Tk5nMrpmZdEtqSrY2YpwMNAvruvN7MfAym1vN8MKoO9K5XdKD8I3rPq3CZWTW1HczDieQXV/187ZGYJQWgf7fhHjnW4ynEPVzluCrD/GGqUJkItemloupjZkUAfT+Vt3JYD2UeWm1lS0NUBsBtIC54fCfWtwVzr0Yyy+QC4FlgRBG4plSdJZ0ZuFExXu9PMzggWXROxOrKGY7Ec6B48/wdw5ZGuFzPLPJYDBeci2gNrjqMOCTkFvTQ0y4Drg5kDM4E/BP3gVwC/NLMFwHzg9GD7J4BHgi6dg8CfqOzi+CuVMw8elbuvCZ5+EHz9ENgR9HlXdSPwUHAyNrLl/B6VJ18jT8ZG43VgdFDHEuCnwPTgezzW6YOHArOCGU5FvkCzV0qDEdzW7rWmclNvq7xJ91Pufl4MjvUAMNXd/1H3yiRs1KIXiRN33wj8KRYXTAGLFfJSE7XoRURCTi16EZGQU9CLiIScgl5EJOQU9CIiIaegFxEJuf8PsEkCr5EdF3QAAAAASUVORK5CYII=%0A)\n",
    "\n",
    "\n",
    "Answer:\n",
    "\n",
    "-first we need to  import our libraries as per the requirements.             \n",
    "\n",
    "example:-                                                                  \n",
    "\n",
    "-and we need to create the table with data beongs to that graph \n",
    "\n",
    "by mesuring data we can find the particular graph,.........simple..! \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
